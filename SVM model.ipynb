{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27d86f2",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) model\n",
    "\n",
    "This is the code to run the best trained SVM model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d2a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EarlyStopping\n",
    "\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec41fd83",
   "metadata": {},
   "source": [
    "## Preparing test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a20a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing preprocessed test set data\n",
    "test_dataset = pd.read_csv('test_dataset.csv') \n",
    "\n",
    "# Split the test data into features (X_test) and target variable (y_test)\n",
    "X_test = test_dataset.iloc[:, :-1]  \n",
    "y_test = test_dataset.iloc[:, -1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee85c77",
   "metadata": {},
   "source": [
    "## Loading pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14487a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model from a file using 'pickle'. \n",
    "with open('best_svm.pkl', 'rb') as file:\n",
    "    best_model_svm = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167cf42",
   "metadata": {},
   "source": [
    "## Testing on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e95569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_svm = best_model_svm.predict(X_test)\n",
    "\n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute testing time\n",
    "testing_time = end_time - start_time\n",
    "print(\"Testing Time:\", testing_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91afa69",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "roc_auc_svm = roc_auc_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1 Score:\", f1_svm)\n",
    "print(\"ROC AUC Score:\", roc_auc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de88773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix_svm, cmap='Blues', annot=True, fmt='d', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "# Adjust the tick labels\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['Neutral or dissatisfied', 'Satisfied'])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['Neutral or dissatisfied', 'Satisfied'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2701628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve and AUC\n",
    "fpr_svm, tpr_svm, _= roc_curve(y_test, y_pred_svm)\n",
    "roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_svm, tpr_svm, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_svm)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
